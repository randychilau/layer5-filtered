---
title: "Service Mesh Architecture and Components"
thumbnail: ./service-mesh.svg
category: Service mesh
tags:
 - Service mesh
 - Network Planes
featured: false
published: true
---

import { Link } from "gatsby";
import { TopicsWrapper } from "../Topics.style.js";
import Planes from "./epsm_0101.png";
import Topology from "./epsm_0102.png";
import Architecture from "./epsm_0103.png";
import Meshery from "./epsm_0112.png";

<TopicsWrapper>
  <div className="intro">
    <p>Learn more about service mesh fundamentals in
      <Link className="blog" to="/learn/books">The Enterprise Path to Service Mesh Archictures (2nd Edition)</Link> -  free book and excellent resource which addresses how to evaluate your organization’s readiness, provides factors to consider when building new applications and converting existing applications to best take advantage of a service mesh, and offers insight on deployment architectures used to get you there.</p>
  </div>

<p>
Although there are a few variants, service mesh architectures commonly comprise three planes: a management plane, a control plane and data plane. The concept of these three planes immediately resonate with network engineers by the analogous way in which physical networks (and their equipment) are designed and managed. Network engineers have long been trained on divisions of concern by planes
</p>

 <div className="right" >
  <img src={Planes} align="right" alt="Network Planes" />
  <p>Figure 1: Physical networking versus software-defined networking planes</p>
 </div>

<p>
Other training that network engineers receive is that of the OSI model. The OSI model is shown in Figure 1 as a refresher for those who have not seen it in some time. We will refer to various layers of this model throughout the book.
</p>

<p>Let’s contrast physical networking planes and network topologies with those of service meshes:</p>

<h3>Physical network planes</h3>

<p>
The physical network data plane (also known as the forwarding plane) contains application traffic generated by hosts, clients, servers, and applications that use the network as transport. Thus, data plane traffic should never have source or destination IP addresses that belong to any network elements such as routers and switches; rather, they should be sourced from and delivered to end devices such as PCs and servers. Routers and switches use hardware chips—application-specific integrated circuits (ASICs)—to forward data plane traffic as quickly as possible. The physical networking data plane references a forwarding information base (FIB). A forwarding information base is a simple, dynamic table that maps a media access control address (MAC address) to a physical network port to transit traffic at wire speed (using ASICs) to the next device.
</p>

<p>
  The physical networking control plane operates as the logical entity associated with router processes and functions used to create and maintain necessary intelligence about the state of the network (topology) and a router’s interfaces. The control plane includes network protocols, such as routing, signaling, and link-state protocols that are used to build and maintain the operational state of the network and provide IP connectivity between IP hosts. Physical network control planes operate in-band of network traffic leaving them susceptible to Denial of service (DoS) attacks that either directly or indirectly result in:
</p>

<ul>
  <li>Exhaustion of memory and/or buffer resources.</li>
  <li>Loss of routing protocol updates and keepalives.</li>
  <li>Slow or blocked access to interactive management sessions.</li>
  <li>High CPU utilization.</li>
  <li>Routing instability, interrupted network reachability, or inconsistent packet delivery.</li>
</ul>

<p>
The physical networking management plane is the logical entity that describes the traffic used to access, manage, and monitor all of the network elements commonly using protocols like SNMP, SSH, HTTPS, and heaven forbid, Telnet. The management plane supports all required provisioning, maintenance, and monitoring functions for the network. Although network traffic in the control plane is handled in-band with all other data plane traffic, management plane traffic is capable of being carried via a separate out-of-band (OOB) management network to provide separate reachability in the event that the primary in-band IP path is not available (and create a security boundary). Restricting management plane access to devices on trusted networks is critical.
</p>

<p>
Physical networking control and data planes are tightly coupled and generally vendor-provided as a proprietary integration of hardware and firmware. Software-defined networking (SDN) has done much to standardize and decouple. OpenvSwitch and OpenDaylight are two examples of SDN projects. We’ll see that control and data planes of service meshes are not necessarily tightly coupled.
</p>

  <div className="left" >
  <img src={Topology} align="right" alt="Mesh Topology" />
  <p>Figure 2: Mesh topology—fully connected network nodes</p>
  </div>

<h3>Physical network topologies</h3>

<p>
Common physical networking topologies include star, spoke-and-hub, tree (also called hierarchical), and mesh. As depicted in Figure 1, nodes in mesh networks connect directly and non-hierarchically such that each node is connected to an arbitrary number (usually as many as possible or as needed dynamically) of neighbor nodes so that there is at least one path from a given node to any other node to efficiently route data.
</p>

<p>
When I designed mesh networks as an engineer at Cisco, I did so to create fully interconnected, wireless networks. Wireless is the canonical use case for physical mesh networks in which the networking medium is readily susceptible to line-of-sight, weather-induced, or other disruption, and therefore, in which reliability is of paramount concern. Mesh networks generally self-configure, enabling dynamic distribution of workloads. This ability is particularly key to both mitigate risk of failure (improve resiliency) and to react to continuously changing topologies. It’s readily apparent why this network topology, shown in Figure 2, is the design of choice for service mesh architectures.
</p>

<h3>Service mesh network planes</h3>

<p>Service mesh architectures typically employ the same three networking planes: data, control, and management. </p>

<div className="right" >
<img src={Architecture} align="right" alt="Service mesh architecture" />
<p>Figure 3: An example of service mesh architecture. In Conduit’s architecture, control and data planes divide in-band and out-of-band responsibility for service traffic</p>
</div>

<p>A service mesh data plane (otherwise known as the proxying layer) intercepts every packet in the request and is responsible for health checking, routing, load balancing, authentication, authorization, and generation of observable signals. Service proxies are transparently inserted, and as applications make service-to-service calls, applications are unaware of the data plane’s existence. Data planes are responsible for intra-service communication as well as inbound (ingress) and outbound (egress) service mesh traffic. Whether traffic is entering the mesh (ingressing) or leaving the mesh (egressing), application service traffic is directed first to the service proxy for handling prior to sending (or not sending) along to the application. In order to redirect traffic from the service proxy to the service application, traffic is transparently intercepted and redirected to the service proxy. The interception and redirection of traffic between the service proxy and service application places the service application’s container onto a network it would otherwise not be on. The service proxy sees all traffic to and from the service application (with small exception, this is the case in most service mesh architectures). Service proxies are the building blocks of service mesh data planes.
</p>

<div class="fact">
Traffic Interception and Redirection:
<p>Service meshes vary in the technology used to intercept and redirect traffic. Some  meshes are flexible in the choice of whether a given deployment uses iptables, IPVS, or eBPF as the technology to transparently proxy requests between clients and service applications. Less transparently, other service mesh proxies simply require that application traffic be configured to direct their traffic to the proxy. The choice between each of these technologies affects the speed by which packets are processed and places environmental constraints on the type and kernel version of the operating system used for the service mesh deployment.</p>
</div>

<p>Envoy is an example of a popular proxy used in service mesh data planes. It is also often found deployed more simply standalone as a load balancer or ingress gateway. The proxies used in service mesh data planes are highly intelligent and may incorporate any number of protocol-specific filters to manipulate network packets (including application level data). With technology advances like WebAssembly, extending data plane capabilities means that service meshes are capable of injecting new logic into requests while simultaneously handling high traffic load.
</p>

<p>
  A service mesh control plane is called for when the number of proxies becomes unwieldy or when a single point of visibility and control is required. Control planes provide policy and configuration for services in the mesh, taking a set of isolated, stateless proxies and turning them into a service mesh. Control planes do not directly touch any network packets in the mesh; they operate out-of-band. Control planes typically have a command-line interface (CLI) and user interface with which to interact, each of which provides access to a centralized API for holistically controlling proxy behavior. You can automate changes to the control plane configuration through its APIs (e.g., by a continuous integration/continuous deployment pipeline), where, in practice, configuration is most often version controlled and updated.
</p>

<div class="fact">
  Proxies are generally considered stateless, but this is a thought-provoking concept. In the way in which proxies are generally informed by the control plane of the presence of services, mesh topology updates, traffic and authorization policy, and so on, proxies cache the state of the mesh but aren’t regarded as the source of truth for the state of the mesh.
</div>

<p>
  Reflecting on Linkerd (pronounced “linker-dee”) and Istio (pronounced “Ist-tee-oh”) as two popular, open source service meshes, we find examples of how the data and control planes are packaged and deployed. In terms of packaging, Linkerdv1 contains both its proxying components (linkerd) and its control plane (namerd) packaged together simply as “Linkerd”, and Istio brings a collection of control plane components (Galley, Pilot, and Citadel) to pair by default with Envoy (a data plane), all packaged together as “Istio.” Envoy is often labeled a service mesh, inappropriately so, because it takes packaging with a control plane to form a service mesh. 
</p>

<p>
  A service mesh management plane is a higher order level of control as shown in Figure 4. A management plane may provide a variety of functions. As such, implementations vary in their functionality: some focusing on orchestrating service meshes (e.g., service mesh lifecycle management) and mesh federation, providing insight across a collection of diverse meshes. Some management planes focus on integrating service meshes with business process and policy, including governance, compliance, validation of configuration, and extensible access control.
</p>

  <div className="left" >
  <img src={Meshery} align="right" alt="Meshery" />
  <p>Figure 4: Meshery, the service mesh management plane’s architecture.</p>
  </div>

<p>
  In terms of deployments of these planes, data planes, like that of Linkerdv2, have proxies that are created as part of the project and are not designed to be configured by hand, but are instead designed for their behavior to be entirely driven by the control plane. Other service meshes, like Istio, choose not to develop their own proxy; instead, they ingest and use independent proxies (separate projects), which, as a result, facilitates choice of proxy and its deployment outside of the mesh (standalone). In terms of control plane deployment, using Kubernetes as the example infrastructure, control planes are typically deployed in a separate “system” namespace. Management planes are deployed both on and off cluster, depending upon how deeply they integrate with non-containerized workloads and a business’s backend systems.
</p>

</TopicsWrapper>
